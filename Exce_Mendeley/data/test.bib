@article{Bodenmann2017,
abstract = {3D visual mapping of the seafloor has found applications ranging from environment monitoring and survey of marine minerals to underwater archaeology and inspection of modern artificial structures. However, the attenuation of light is significantly more pronounced in water than in air or in space, and so in order to obtain underwater images in colour, it is typically necessary to be within 2â€“3 m of the seafloor. In addition to the high risk of collision when operating underwater vehicles at such low altitudes, the limited area of the seafloor covered in each image means large area surveys require a significant investment of time. In this research, we aim to increase the efficiency of mapping large areas of the seafloor by developing an underwater imaging system that can take colour images at ranges of more than 10 m, so that each image can cover a larger area, together with the necessary algorithms to automatically process the data it obtains. The system was deployed to map artificial hydrothermal vents in Iheya North field using the ROV Hyper-Dolphin in October 2012. The surveyed area is of particular interest to the research community, as multiple artificial vent holes were drilled during a mission in 2010, which locally impacted the flow of hydrothermal fluids. In this paper, we describe the methods used to process the data that the imaging system obtains and demonstrate how the mapping data can be used in quantitative studies of the seafloor. Habitats of Shinkaia crosnieri squat lobsters, which are abundant in the hydrothermally active areas, are identified in the maps and their population density calculated, and the amount of hydrothermal deposits that have grown on the artificial vent is derived from the mapping data. The work demonstrates how 3D visual mapping can be applied to benthic biology and geological studies.},
author = {Bodenmann, Adrian and Thornton, Blair and Nakajima, Ryota and Ura, Tamaki},
doi = {10.1186/s40648-017-0091-5},
file = {:media/documentos/Drive USB/Publicaciones/2017/2017{\_}Bodenmann et al.{\_}Methods for quantit.{\_}Methods for quantitative studies of seafloor hydrothermal systems using 3D visual reconstructions:{\_}Methods for quantitative studies of seafloor hydrothermal systems using 3D visual reconstructions},
isbn = {2197-4225},
issn = {2197-4225},
journal = {ROBOMECH Journal},
keywords = {3d mapping,Underwater,3D mapping,Information extraction,Deep-,deep-sea hydrothermal vents,information extraction,underwater},
number = {1},
pages = {22},
publisher = {Springer International Publishing},
title = {{Methods for quantitative studies of seafloor hydrothermal systems using 3D visual reconstructions}},
url = {http://robomechjournal.springeropen.com/articles/10.1186/s40648-017-0091-5},
volume = {4},
year = {2017}
}
@inproceedings{Jancosek2011,
abstract = {We propose a novel method for the multi-view reconstruction problem. Surfaces which do not have direct support in the input 3D point cloud and hence need not be photo-consistent but represent real parts of the scene (e.g. low-textured walls, windows, cars) are important for achieving complete reconstructions. We augmented the existing Labatut CGF 2009 method with the ability to cope with these difficult surfaces just by changing the t-edge weights in the construction of surfaces by a minimal s-t cut. Our method uses Visual-Hull to reconstruct the difficult surfaces which are not sampled densely enough by the input 3D point cloud. We demonstrate importance of these surfaces on several real-world data sets. We compare our improvement to our implementation of the Labatut CGF 2009 method and show that our method can considerably better reconstruct difficult surfaces while preserving thin structures and details in the same quality and computational time.},
author = {Jancosek, Michal and Pajdla, Tomas},
booktitle = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2011.5995693},
file = {:media/documentos/Drive USB/Publicaciones/2011/2011{\_}Jancosek, Pajdla{\_}Multi-view reconstruction preserving weakly-supported surfaces.pdf:pdf},
isbn = {9781457703942},
issn = {10636919},
pages = {3121--3128},
title = {{Multi-view reconstruction preserving weakly-supported surfaces}},
year = {2011}
}
@article{Arnott2005,
abstract = {Effective marine archaeological site management demands detailed information on not only the spatial distribution of artefacts but also the degradation state of the materials present. Although sonar methods have frequently been used in an attempt to detect buried wooden shipwrecks they are currently unable to indicate their degradation state. To assess the sensitivity of acoustic measurements to changes in the degradation state of such material, and hence the potential for sonars to quantify degradation, laboratory measurements of compressional wave velocity, as well as bulk density for oak and pine samples, in varying states of decay, were undertaken. These data enabled the calculation of theoretical reflection coefficients for such materials buried in various marine sediments. As wood degrades, the reflection coefficients become more negative, resulting in the hypothesis that the more degraded wood becomes, the easier it should be to detect. Typical reflection coefficients of the order of -0.43 and -0.52 for the most degraded oak and pine samples in sand are predicted. Conversely, for wood exposed to seawater the predicted reflection coefficients are large and positive for undegraded material (0.35 for oak, 0.18 for pine) and decrease to zero or slightly below for the most degraded samples. This indicates that exposed timbers, when heavily degraded, can be acoustically transparent and so undetectable by acoustic methods. Corroboration of these experimental results was provided through comparison with high resolution seismic reflection data that has been acquired over two shipwrecks.},
author = {Arnott, Stephanie H.L. and Dix, Justin K. and Best, Angus I. and Gregory, David J.},
doi = {10.1007/s11001-005-3713-x},
file = {:media/documentos/Drive USB/Publicaciones/2005/2005{\_}Arnott et al.{\_}Imaging of buried archaeological materials The reflection properties of archaeological wood.pdf:pdf},
isbn = {0025-3235},
issn = {00253235},
journal = {Marine Geophysical Researches},
keywords = {Acoustics,Archaeology,Chirp,Compressional wave velocity,Reflection coefficient,Shipwreck,Sonar,Sub-bottom profiler},
number = {2-4},
pages = {135--144},
title = {{Imaging of buried archaeological materials: The reflection properties of archaeological wood}},
volume = {26},
year = {2005}
}
@article{Torres2007,
abstract = {This work exploits the resemblance between content-based image retrieval and image analysis with respect to the design of image descriptors and their effectiveness. In this context, two shape descriptors are proposed: contour saliences and segment saliences. Contour saliences revisits its original definition, where the location of concave points was a problem, and provides a robust approach to incorporate concave saliences. Segment saliences introduces salience values for contour segments, making it possible to use an optimal matching algorithm as distance function. The proposed descriptors are compared with convex contour saliences, curvature scale space, and beam angle statistics using a fish database with 11,000 images organized in 1100 distinct classes. The results indicate segment saliences as the most effective descriptor for this particular application and confirm the improvement of the contour salience descriptor in comparison with convex contour saliences. ?? 2006 Elsevier B.V. All rights reserved.},
author = {Torres, R. da S and Falcao, A. X.},
doi = {10.1016/j.imavis.2005.12.010},
file = {:media/documentos/Drive USB/Publicaciones/2007/2007{\_}Torres, Falcao{\_}Contour salience descriptors for effective image retrieval and analysis.pdf:pdf},
isbn = {0262-8856},
issn = {02628856},
journal = {Image and Vision Computing},
keywords = {Image foresting transform,Image processing,Image retrieval,Multiscale skeletonization,Shape analysis,Shape exact dilation,Shape saliences},
number = {1},
pages = {3--13},
title = {{Contour salience descriptors for effective image retrieval and analysis}},
volume = {25},
year = {2007}
}
@article{Guo2010,
author = {Guo, Zhenhua and Zhang, Lei and Zhang, David},
doi = {10.1109/TIP.2010.2044957},
file = {:media/documentos/Drive USB/Publicaciones/2010/2010{\_}Guo, Zhang, Zhang{\_}A completed modeling of local binary pattern operator for texture classification.pdf:pdf},
isbn = {1057-7149},
issn = {10577149},
journal = {IEEE Transactions on Image Processing},
keywords = {Local binary pattern (LBP),Rotation invariance,Texture classification},
number = {6},
pages = {1657--1663},
title = {{A completed modeling of local binary pattern operator for texture classification}},
volume = {19},
year = {2010}
}
@article{Tendero,
abstract = {Video sequences can be enhanced by a spatial deconvolution of any motion blur whose support does not exceed two pixels per frame. However, this deconvolution requires an accurate blur estimation and local deconvolution which is dicult for multiple local motions. We provide a discrete temporal lter whose coecients are designed 1) to deconvolve blindly any uniform motion blur whose support does not exceed one pixel per frame, 2) to take into account for the sensor dead time between two consecutive frame (duty ratio/inter frame delay). The proposed lter enjoys optimality properties in terms of mean square error. In addition, it is demonstrated on real movies obtained from a smartphone and the Middlebury dataset.},
author = {Tendero, Yohann and Osher, Stanley},
file = {:media/documentos/Drive USB/Publicaciones/Unknown/Unknown{\_}Tendero, Osher{\_}Blind uniform motion blur deconvolution for image bursts and video sequences based on sensor characteristics.pdf:pdf},
isbn = {0001412108},
journal = {Math.Ucla.Edu},
keywords = {blind deconvolution,coded exposure,flutter shutter,motion blur,poisson noise},
pages = {1--8},
title = {{Blind uniform motion blur deconvolution for image bursts and video sequences based on sensor characteristics}},
url = {ftp://ftp.math.ucla.edu/pub/camreport/cam14-17.pdf}
}
@article{Li2016,
abstract = {Restoring underwater image from a single image is know to be ill-posed, and some assumptions made in previous methods are not suitable for many situations. In this paper, we propose a method based on blue-green channels dehazing and red channel correction for underwater image restoration. Firstly, blue-green channels are recovered via dehazing algorithm based on an extension and modification of Dark Channel Prior algorithm. Then, red channel is corrected following the Gray-World assumption theory. Finally, in order to resolve the problem which some recovered image regions may look too dim or too bright, an adaptive exposure map is built. Qualitative analysis demonstrates that our method significantly improves visibility and contrast, and reduces the effects of light absorption and scattering. For quantitative analysis, our results obtain best values in terms of entropy, local feature points and average gradient, which outperform three existing physical model available methods.},
author = {Li, Chongyi and Quo, Jichang and Pang, Yanwei and Chen, Shanji and Wang, Jian},
doi = {10.1109/ICASSP.2016.7471973},
file = {:media/documentos/Drive USB/Publicaciones/2016/2016{\_}Li et al.{\_}Single underwater image restoration by blue-green channels dehazing and red channel correction.pdf:pdf},
isbn = {9781479999880},
issn = {15206149},
journal = {ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
keywords = {Underwater image restoration,image de-hazing,image enhancement,visibility recovery},
pages = {1731--1735},
title = {{Single underwater image restoration by blue-green channels dehazing and red channel correction}},
volume = {2016-May},
year = {2016}
}
@article{Bryson2017,
abstract = {{\textcopyright} 2017 The Authors. Ecology and Evolution published by John Wiley {\&} Sons Ltd. Habitat structural complexity is one of the most important factors in determining the makeup of biological communities. Recent advances in structure-from-motion and photogrammetry have resulted in a proliferation of 3D digital representations of habitats from which structural complexity can be measured. Little attention has been paid to quantifying the measurement errors associated with these techniques, including the variability of results under different surveying and environmental conditions. Such errors have the potential to confound studies that compare habitat complexity over space and time. This study evaluated the accuracy, precision, and bias in measurements of marine habitat structural complexity derived from structure-from-motion and photogrammetric measurements using repeated surveys of artificial reefs (with known structure) as well as natural coral reefs. We quantified measurement errors as a function of survey image coverage, actual surface rugosity, and the morphological community composition of the habitat-forming organisms (reef corals). Our results indicated that measurements could be biased by up to 7.5{\%} of the total observed ranges of structural complexity based on the environmental conditions present during any particular survey. Positive relationships were found between measurement errors and actual complexity, and the strength of these relationships was increased when coral morphology and abundance were also used as predictors. The numerous advantages of structure-from-m otion and photogrammetry techniques for quantifying and investigating marine habitats will mean that they are likely to replace traditional measurement techniques (e.g., chain-and-tape). To this end, our results have important implications for data collection and the interpretation of measurements when examining changes in habitat complexity using structure-from-motion and photogrammetry.},
author = {Bryson, Mitch and Ferrari, Renata and Figueira, Will and Pizarro, Oscar and Madin, Josh and Williams, Stefan B. and Byrne, Maria},
doi = {10.1002/ece3.3127},
file = {:media/documentos/Drive USB/Publicaciones/2017/2017{\_}Bryson et al.{\_}Characterization of measurement errors using structure-from-motion and photogrammetry to measure marine habitat struc.pdf:pdf},
issn = {20457758},
journal = {Ecology and Evolution},
number = {15},
title = {{Characterization of measurement errors using structure-from-motion and photogrammetry to measure marine habitat structural complexity}},
volume = {7},
year = {2017}
}
@book{Sousa2012,
abstract = {The global market offers an extensive catalog of commercial Autonomous Underwater Vehicles with different shapes, sizes and capabilities. This paper addresses the innovative concept which led to the development of a new commercial AUV product to compete in such a dynamic market. The LAUV was planned to be a lightweight vehicle that can be easily launched, operated and recovered with a minimal operational setup by end-users having heterogeneous backgrounds and without any complex prior training or know-how. Details of the design, installed components, sensors, sonars and operational field results, are discussed herein. The system has been deployed and operated in different environments for different objectives accumulating hundreds of successful real-world missions.},
author = {Sousa, Alexandre and Madureira, Luis and Coelho, Jorge and Pinto, Jos{\'{e}} and Pereira, Jo{\~{a}}o and Sousa, Jo{\~{a}}o Borges and Dias, Paulo},
booktitle = {IFAC Proceedings Volumes (IFAC-PapersOnline)},
doi = {10.3182/20120410-3-PT-4028.00045},
file = {:media/documentos/Drive USB/Publicaciones/2012/2012{\_}Sousa et al.{\_}LAUV The man-portable autonomous underwater vehicle.pdf:pdf},
isbn = {9783902823199},
issn = {14746670},
keywords = {Autonomous Underwater Vehicles,Data collection,Marine Systems,Mechanical,Robotics,Systems Engineering},
number = {PART 1},
pages = {268--274},
publisher = {IFAC},
title = {{LAUV: The man-portable autonomous underwater vehicle}},
url = {http://dx.doi.org/10.3182/20120410-3-PT-4028.00045},
volume = {3},
year = {2012}
}
@article{Stetson2008,
author = {Stetson, P and Shank, B and Lobel, P S},
file = {:media/documentos/Drive USB/Publicaciones/2008/2008{\_}Stetson, Shank, Lobel{\_}Mapping reef structure and bathymetry in Belize using.pdf:pdf},
journal = {11th International Coral Reef Symposium.},
keywords = {cobra-tac,doppler device,reef mapping,underwater navigation},
number = {16},
pages = {7--11},
title = {{Mapping reef structure and bathymetry in Belize using}},
year = {2008}
}
@inproceedings{Mindru1999,
author = {Mindru, F and Moons, T and {Van Gool}, L},
booktitle = {CVPR},
file = {:media/documentos/Drive USB/Publicaciones/1999/1999{\_}Mindru, Moons, Van Gool{\_}Recognizing color patterns irrexpective of viewpoint an illumination.pdf:pdf},
keywords = {juergen},
pages = {368--373},
title = {{Recognizing color patterns irrexpective of viewpoint an illumination}},
year = {1999}
}
@article{Eustice2005b,
abstract = {Page 1. the with Ryan Eustice and Hanumant Singh Woods Hole Oceanographic Institution Woods Hole, MA, USA {\{}ryan,hanu{\}}@whoi.edu John Leonard and Matthew},
author = {Eustice, Ryan Michael and Singh, Hanumant},
file = {:media/documentos/Drive USB/Publicaciones/2005/2005{\_}Eustice, Singh{\_}Visually navigating the {\{}RMS{\}} Titanic with {\{}SLAM{\}} information filters.pdf:pdf},
isbn = {9780262701143},
issn = {2330765X},
journal = {Robotics: Science and Systems},
pages = {57--64},
title = {{Visually navigating the {\{}RMS{\}} Titanic with {\{}SLAM{\}} information filters}},
year = {2005}
}
@article{Takahashi2018,
author = {Takahashi, Tomoko and Thornton, Blair and Sato, Takumi and Ohki, Toshihiko and Ohki, Koichi and Sakka, Tetsuo},
doi = {10.1364/ao.57.005872},
file = {:media/documentos/Drive USB/Publicaciones/2018/2018{\_}Takahashi et al.{\_}Partial least squares regression calculation for quantitative analysis of metals submerged in water measured using.pdf:pdf},
issn = {1559-128X},
journal = {Applied Optics},
number = {20},
pages = {5872},
title = {{Partial least squares regression calculation for quantitative analysis of metals submerged in water measured using laser-induced breakdown spectroscopy}},
volume = {57},
year = {2018}
}
@article{Anelli2019,
abstract = {Photogrammetry represents a non-destructive, cost-effective tool for coral reef monitoring, able to integrate traditional remote sensing techniques and support researchers' work. However, its application to submerged habitats is still in early stage. We present new ways to employ Structure from Motion techniques to infer properties of reef habitats. In particular, we propose the use of Digital Surface Models and Digital Terrain Models for assessing coral colonies extension and height and discriminating between seabed and coral cover. Such information can be coupled with digital rugosity estimates to improve habitat characterization. DTM, DSM and orthophotos were derived and used to compute a series of metrics like coral morphologies, reef topography, coral cover and structural complexity. We show the potentialities offered by underwater photogrammetry and derived products to provide useful basic information for marine habitat mapping, opening the possibility to extend these methods for large-scale assessment and monitoring of coral reefs.},
author = {Anelli, Martina and Julitta, Tommaso and Fallati, Luca and Galli, Paolo and Rossini, Micol and Colombo, Roberto},
doi = {10.1080/10106049.2017.1408703},
file = {:media/documentos/Drive USB/Publicaciones/2019/2019{\_}Anelli et al.{\_}Towards new applications of underwater photogrammetry for investigating coral reef morphology and habitat complexity.pdf:pdf},
issn = {1010-6049},
journal = {Geocarto International},
month = {apr},
number = {5},
pages = {459--472},
title = {{Towards new applications of underwater photogrammetry for investigating coral reef morphology and habitat complexity in the Myeik Archipelago, Myanmar}},
url = {https://www.tandfonline.com/doi/full/10.1080/10106049.2017.1408703},
volume = {34},
year = {2019}
}
